{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e6b9614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load data from a CSV file into a pandas DataFrame.\"\"\"\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76c0d10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(355190, 116)\n"
     ]
    }
   ],
   "source": [
    "df = load_data('data/bank_data_train.csv')\n",
    "TRESHOLD = 0.7\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a8ee35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 355190 entries, 0 to 355189\n",
      "Columns: 116 entries, ID to TARGET\n",
      "dtypes: float64(94), int64(9), object(13)\n",
      "memory usage: 314.3+ MB\n",
      "\n",
      "Dropped column: 'ID'\n",
      "\n",
      "DataFrame Description (numeric):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CR_PROD_CNT_IL</th>\n",
       "      <th>AMOUNT_RUB_CLO_PRC</th>\n",
       "      <th>PRC_ACCEPTS_A_EMAIL_LINK</th>\n",
       "      <th>APP_REGISTR_RGN_CODE</th>\n",
       "      <th>PRC_ACCEPTS_A_POS</th>\n",
       "      <th>PRC_ACCEPTS_A_TK</th>\n",
       "      <th>TURNOVER_DYNAMIC_IL_1M</th>\n",
       "      <th>CNT_TRAN_AUT_TENDENCY1M</th>\n",
       "      <th>SUM_TRAN_AUT_TENDENCY1M</th>\n",
       "      <th>AMOUNT_RUB_SUP_PRC</th>\n",
       "      <th>...</th>\n",
       "      <th>REST_DYNAMIC_CC_3M</th>\n",
       "      <th>MED_DEBT_PRC_YWZ</th>\n",
       "      <th>LDEAL_ACT_DAYS_PCT_TR3</th>\n",
       "      <th>LDEAL_ACT_DAYS_PCT_AAVG</th>\n",
       "      <th>LDEAL_DELINQ_PER_MAXYWZ</th>\n",
       "      <th>TURNOVER_DYNAMIC_CC_3M</th>\n",
       "      <th>LDEAL_ACT_DAYS_PCT_TR</th>\n",
       "      <th>LDEAL_ACT_DAYS_PCT_TR4</th>\n",
       "      <th>LDEAL_ACT_DAYS_PCT_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>355190.000000</td>\n",
       "      <td>316867.000000</td>\n",
       "      <td>155163.0</td>\n",
       "      <td>60550.000000</td>\n",
       "      <td>155163.0</td>\n",
       "      <td>155163.0</td>\n",
       "      <td>355190.000000</td>\n",
       "      <td>77112.000000</td>\n",
       "      <td>77112.000000</td>\n",
       "      <td>316867.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>355190.000000</td>\n",
       "      <td>95713.000000</td>\n",
       "      <td>93448.000000</td>\n",
       "      <td>98175.000000</td>\n",
       "      <td>95713.000000</td>\n",
       "      <td>355190.000000</td>\n",
       "      <td>93448.000000</td>\n",
       "      <td>93448.000000</td>\n",
       "      <td>93448.000000</td>\n",
       "      <td>355190.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.105225</td>\n",
       "      <td>0.044045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.947498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.416896</td>\n",
       "      <td>0.414572</td>\n",
       "      <td>0.085249</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007309</td>\n",
       "      <td>0.055074</td>\n",
       "      <td>0.025707</td>\n",
       "      <td>0.049943</td>\n",
       "      <td>0.009252</td>\n",
       "      <td>0.004309</td>\n",
       "      <td>0.013938</td>\n",
       "      <td>0.013938</td>\n",
       "      <td>0.013938</td>\n",
       "      <td>0.081435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.431372</td>\n",
       "      <td>0.108449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.777855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029118</td>\n",
       "      <td>0.316493</td>\n",
       "      <td>0.338612</td>\n",
       "      <td>0.142310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066681</td>\n",
       "      <td>0.215909</td>\n",
       "      <td>0.115732</td>\n",
       "      <td>0.185830</td>\n",
       "      <td>0.092789</td>\n",
       "      <td>0.059852</td>\n",
       "      <td>0.097099</td>\n",
       "      <td>0.097099</td>\n",
       "      <td>0.097099</td>\n",
       "      <td>0.273503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.139645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.027117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.661195</td>\n",
       "      <td>0.110005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CR_PROD_CNT_IL  AMOUNT_RUB_CLO_PRC  PRC_ACCEPTS_A_EMAIL_LINK  \\\n",
       "count   355190.000000       316867.000000                  155163.0   \n",
       "mean         0.105225            0.044045                       0.0   \n",
       "std          0.431372            0.108449                       0.0   \n",
       "min          0.000000            0.000000                       0.0   \n",
       "25%          0.000000            0.000000                       0.0   \n",
       "50%          0.000000            0.000000                       0.0   \n",
       "75%          0.000000            0.036608                       0.0   \n",
       "max         11.000000            1.000000                       0.0   \n",
       "\n",
       "       APP_REGISTR_RGN_CODE  PRC_ACCEPTS_A_POS  PRC_ACCEPTS_A_TK  \\\n",
       "count          60550.000000           155163.0          155163.0   \n",
       "mean              50.947498                0.0               0.0   \n",
       "std               21.777855                0.0               0.0   \n",
       "min                0.000000                0.0               0.0   \n",
       "25%               33.000000                0.0               0.0   \n",
       "50%               54.000000                0.0               0.0   \n",
       "75%               72.000000                0.0               0.0   \n",
       "max               89.000000                0.0               0.0   \n",
       "\n",
       "       TURNOVER_DYNAMIC_IL_1M  CNT_TRAN_AUT_TENDENCY1M  \\\n",
       "count           355190.000000             77112.000000   \n",
       "mean                 0.001305                 0.416896   \n",
       "std                  0.029118                 0.316493   \n",
       "min                  0.000000                 0.006944   \n",
       "25%                  0.000000                 0.166667   \n",
       "50%                  0.000000                 0.300000   \n",
       "75%                  0.000000                 0.571429   \n",
       "max                  1.000000                 1.000000   \n",
       "\n",
       "       SUM_TRAN_AUT_TENDENCY1M  AMOUNT_RUB_SUP_PRC  ...  REST_DYNAMIC_CC_3M  \\\n",
       "count             77112.000000       316867.000000  ...       355190.000000   \n",
       "mean                  0.414572            0.085249  ...            0.007309   \n",
       "std                   0.338612            0.142310  ...            0.066681   \n",
       "min                   0.000000            0.000000  ...            0.000000   \n",
       "25%                   0.139645            0.000000  ...            0.000000   \n",
       "50%                   0.285714            0.027117  ...            0.000000   \n",
       "75%                   0.661195            0.110005  ...            0.000000   \n",
       "max                   1.000000            1.000000  ...            1.000000   \n",
       "\n",
       "       MED_DEBT_PRC_YWZ  LDEAL_ACT_DAYS_PCT_TR3  LDEAL_ACT_DAYS_PCT_AAVG  \\\n",
       "count      95713.000000            93448.000000             98175.000000   \n",
       "mean           0.055074                0.025707                 0.049943   \n",
       "std            0.215909                0.115732                 0.185830   \n",
       "min            0.000000                0.000000                 0.000000   \n",
       "25%            0.000000                0.000000                 0.000000   \n",
       "50%            0.000000                0.000000                 0.000000   \n",
       "75%            0.000000                0.000000                 0.000000   \n",
       "max            1.000000                1.000000                 1.000000   \n",
       "\n",
       "       LDEAL_DELINQ_PER_MAXYWZ  TURNOVER_DYNAMIC_CC_3M  LDEAL_ACT_DAYS_PCT_TR  \\\n",
       "count             95713.000000           355190.000000           93448.000000   \n",
       "mean                  0.009252                0.004309               0.013938   \n",
       "std                   0.092789                0.059852               0.097099   \n",
       "min                   0.000000                0.000000               0.000000   \n",
       "25%                   0.000000                0.000000               0.000000   \n",
       "50%                   0.000000                0.000000               0.000000   \n",
       "75%                   0.000000                0.000000               0.000000   \n",
       "max                   1.000000                1.000000               1.000000   \n",
       "\n",
       "       LDEAL_ACT_DAYS_PCT_TR4  LDEAL_ACT_DAYS_PCT_CURR         TARGET  \n",
       "count            93448.000000             93448.000000  355190.000000  \n",
       "mean                 0.013938                 0.013938       0.081435  \n",
       "std                  0.097099                 0.097099       0.273503  \n",
       "min                  0.000000                 0.000000       0.000000  \n",
       "25%                  0.000000                 0.000000       0.000000  \n",
       "50%                  0.000000                 0.000000       0.000000  \n",
       "75%                  0.000000                 0.000000       0.000000  \n",
       "max                  1.000000                 1.000000       1.000000  \n",
       "\n",
       "[8 rows x 102 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Description (object):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLNT_TRUST_RELATION</th>\n",
       "      <th>APP_MARITAL_STATUS</th>\n",
       "      <th>APP_KIND_OF_PROP_HABITATION</th>\n",
       "      <th>CLNT_JOB_POSITION_TYPE</th>\n",
       "      <th>CLNT_JOB_POSITION</th>\n",
       "      <th>APP_DRIVING_LICENSE</th>\n",
       "      <th>APP_EDUCATION</th>\n",
       "      <th>APP_TRAVEL_PASS</th>\n",
       "      <th>APP_CAR</th>\n",
       "      <th>APP_POSITION_TYPE</th>\n",
       "      <th>APP_EMP_TYPE</th>\n",
       "      <th>APP_COMP_TYPE</th>\n",
       "      <th>PACK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>69421</td>\n",
       "      <td>68234</td>\n",
       "      <td>59361</td>\n",
       "      <td>44781</td>\n",
       "      <td>210811</td>\n",
       "      <td>57257</td>\n",
       "      <td>68104</td>\n",
       "      <td>57257</td>\n",
       "      <td>57256</td>\n",
       "      <td>60545</td>\n",
       "      <td>67362</td>\n",
       "      <td>67362</td>\n",
       "      <td>355190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>19588</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>FRIEND</td>\n",
       "      <td>M</td>\n",
       "      <td>SO</td>\n",
       "      <td>SPECIALIST</td>\n",
       "      <td>ДИРЕКТОР</td>\n",
       "      <td>N</td>\n",
       "      <td>H</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>SPECIALIST</td>\n",
       "      <td>PRIVATE</td>\n",
       "      <td>PRIVATE</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>24896</td>\n",
       "      <td>30724</td>\n",
       "      <td>28056</td>\n",
       "      <td>25123</td>\n",
       "      <td>11200</td>\n",
       "      <td>36332</td>\n",
       "      <td>42459</td>\n",
       "      <td>52750</td>\n",
       "      <td>32843</td>\n",
       "      <td>36622</td>\n",
       "      <td>59087</td>\n",
       "      <td>59087</td>\n",
       "      <td>116986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CLNT_TRUST_RELATION APP_MARITAL_STATUS APP_KIND_OF_PROP_HABITATION  \\\n",
       "count                69421              68234                       59361   \n",
       "unique                  21                 13                           5   \n",
       "top                 FRIEND                  M                          SO   \n",
       "freq                 24896              30724                       28056   \n",
       "\n",
       "       CLNT_JOB_POSITION_TYPE CLNT_JOB_POSITION APP_DRIVING_LICENSE  \\\n",
       "count                   44781            210811               57257   \n",
       "unique                      4             19588                   2   \n",
       "top                SPECIALIST          ДИРЕКТОР                   N   \n",
       "freq                    25123             11200               36332   \n",
       "\n",
       "       APP_EDUCATION APP_TRAVEL_PASS APP_CAR APP_POSITION_TYPE APP_EMP_TYPE  \\\n",
       "count          68104           57257   57256             60545        67362   \n",
       "unique            17               2       2                 4            4   \n",
       "top                H               N       N        SPECIALIST      PRIVATE   \n",
       "freq           42459           52750   32843             36622        59087   \n",
       "\n",
       "       APP_COMP_TYPE    PACK  \n",
       "count          67362  355190  \n",
       "unique             4      12  \n",
       "top          PRIVATE     102  \n",
       "freq           59087  116986  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CR_PROD_CNT_IL</th>\n",
       "      <th>AMOUNT_RUB_CLO_PRC</th>\n",
       "      <th>PRC_ACCEPTS_A_EMAIL_LINK</th>\n",
       "      <th>APP_REGISTR_RGN_CODE</th>\n",
       "      <th>PRC_ACCEPTS_A_POS</th>\n",
       "      <th>PRC_ACCEPTS_A_TK</th>\n",
       "      <th>TURNOVER_DYNAMIC_IL_1M</th>\n",
       "      <th>CNT_TRAN_AUT_TENDENCY1M</th>\n",
       "      <th>SUM_TRAN_AUT_TENDENCY1M</th>\n",
       "      <th>AMOUNT_RUB_SUP_PRC</th>\n",
       "      <th>...</th>\n",
       "      <th>REST_DYNAMIC_CC_3M</th>\n",
       "      <th>MED_DEBT_PRC_YWZ</th>\n",
       "      <th>LDEAL_ACT_DAYS_PCT_TR3</th>\n",
       "      <th>LDEAL_ACT_DAYS_PCT_AAVG</th>\n",
       "      <th>LDEAL_DELINQ_PER_MAXYWZ</th>\n",
       "      <th>TURNOVER_DYNAMIC_CC_3M</th>\n",
       "      <th>LDEAL_ACT_DAYS_PCT_TR</th>\n",
       "      <th>LDEAL_ACT_DAYS_PCT_TR4</th>\n",
       "      <th>LDEAL_ACT_DAYS_PCT_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Missing Values</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38323.000000</td>\n",
       "      <td>200027.000000</td>\n",
       "      <td>294640.000000</td>\n",
       "      <td>200027.000000</td>\n",
       "      <td>200027.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278078.000000</td>\n",
       "      <td>278078.000000</td>\n",
       "      <td>38323.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>259477.000000</td>\n",
       "      <td>261742.000000</td>\n",
       "      <td>257015.000000</td>\n",
       "      <td>259477.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261742.000000</td>\n",
       "      <td>261742.000000</td>\n",
       "      <td>261742.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Percentage</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.789437</td>\n",
       "      <td>56.315493</td>\n",
       "      <td>82.952786</td>\n",
       "      <td>56.315493</td>\n",
       "      <td>56.315493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.289929</td>\n",
       "      <td>78.289929</td>\n",
       "      <td>10.789437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.053014</td>\n",
       "      <td>73.690701</td>\n",
       "      <td>72.359864</td>\n",
       "      <td>73.053014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.690701</td>\n",
       "      <td>73.690701</td>\n",
       "      <td>73.690701</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                CR_PROD_CNT_IL  AMOUNT_RUB_CLO_PRC  PRC_ACCEPTS_A_EMAIL_LINK  \\\n",
       "Missing Values             0.0        38323.000000             200027.000000   \n",
       "Percentage                 0.0           10.789437                 56.315493   \n",
       "\n",
       "                APP_REGISTR_RGN_CODE  PRC_ACCEPTS_A_POS  PRC_ACCEPTS_A_TK  \\\n",
       "Missing Values         294640.000000      200027.000000     200027.000000   \n",
       "Percentage                 82.952786          56.315493         56.315493   \n",
       "\n",
       "                TURNOVER_DYNAMIC_IL_1M  CNT_TRAN_AUT_TENDENCY1M  \\\n",
       "Missing Values                     0.0            278078.000000   \n",
       "Percentage                         0.0                78.289929   \n",
       "\n",
       "                SUM_TRAN_AUT_TENDENCY1M  AMOUNT_RUB_SUP_PRC  ...  \\\n",
       "Missing Values            278078.000000        38323.000000  ...   \n",
       "Percentage                    78.289929           10.789437  ...   \n",
       "\n",
       "                REST_DYNAMIC_CC_3M  MED_DEBT_PRC_YWZ  LDEAL_ACT_DAYS_PCT_TR3  \\\n",
       "Missing Values                 0.0     259477.000000           261742.000000   \n",
       "Percentage                     0.0         73.053014               73.690701   \n",
       "\n",
       "                LDEAL_ACT_DAYS_PCT_AAVG  LDEAL_DELINQ_PER_MAXYWZ  \\\n",
       "Missing Values            257015.000000            259477.000000   \n",
       "Percentage                    72.359864                73.053014   \n",
       "\n",
       "                TURNOVER_DYNAMIC_CC_3M  LDEAL_ACT_DAYS_PCT_TR  \\\n",
       "Missing Values                     0.0          261742.000000   \n",
       "Percentage                         0.0              73.690701   \n",
       "\n",
       "                LDEAL_ACT_DAYS_PCT_TR4  LDEAL_ACT_DAYS_PCT_CURR  TARGET  \n",
       "Missing Values           261742.000000            261742.000000     0.0  \n",
       "Percentage                   73.690701                73.690701     0.0  \n",
       "\n",
       "[2 rows x 115 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET\n",
      "0    326265\n",
      "1     28925\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def explore_data(df):\n",
    "    \"\"\"Display basic information about the DataFrame and drop 'ID' if present. Returns the (possibly) modified DataFrame.\"\"\"\n",
    "    print(\"DataFrame Info:\")\n",
    "    df.info()\n",
    "    \n",
    "    # drop unnecessary column if it exists\n",
    "    if 'ID' in df.columns:\n",
    "        df = df.drop(columns=['ID'])\n",
    "        print(\"\\nDropped column: 'ID'\")\n",
    "    else:\n",
    "        print(\"\\nColumn 'ID' not found; skipping drop.\")\n",
    "    \n",
    "    print(\"\\nDataFrame Description (numeric):\")\n",
    "    display(df.describe())\n",
    "    \n",
    "    print(\"\\nDataFrame Description (object):\")\n",
    "    display(df.describe(include=['object']))\n",
    "    \n",
    "    # optionally show missing values and plot in grid format\n",
    "    print(\"\\nMissing Values:\")\n",
    "    df_info = pd.DataFrame(df.isnull().sum(), columns=['Missing Values'])\n",
    "    df_info['Percentage'] = (df_info['Missing Values'] / len(df)) * 100\n",
    "\n",
    "    # fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    # df_info['Percentage'].plot(kind='bar', ax=ax, color='tab:blue')\n",
    "    # ax.set_title('Missing Values in Each Column')\n",
    "    # ax.set_ylabel('Percentage (%)')\n",
    "    # ax.set_xlabel('Columns')\n",
    "    # plt.xticks(rotation=45, ha='right')\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    \n",
    "    \n",
    "    #siwich column into rows for better display\n",
    "\n",
    "    df_info = df_info.transpose()\n",
    "    display(df_info)\n",
    "    # display(df.isnull().sum())\n",
    "    \n",
    "    # check the distribution of target column\n",
    "    print(df['TARGET'].value_counts())\n",
    "    return df\n",
    "\n",
    "df = explore_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3232174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.918564711844365"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "326265/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24795fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "import numpy as np\n",
    "\n",
    "def cramers_v(x, y):\n",
    "    \"\"\"Measure association between categorical x and binary y (TARGET)\"\"\"\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    return np.sqrt(phi2 / min(k-1, r-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76f00f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing columns with >70% missing values for correlation with TARGET...\n",
      "df shape before dropping columns: (355190, 115)\n",
      "Dropping column APP_REGISTR_RGN_CODE due to low correlation (-0.028) with TARGET\n",
      "Dropping column CLNT_TRUST_RELATION due to low correlation (0.029) with TARGET\n",
      "Dropping column APP_MARITAL_STATUS due to low correlation (0.030) with TARGET\n",
      "Dropping column APP_KIND_OF_PROP_HABITATION due to low correlation (0.008) with TARGET\n",
      "Dropping column CLNT_JOB_POSITION_TYPE due to low correlation (0.036) with TARGET\n",
      "Dropping column APP_DRIVING_LICENSE due to low correlation (0.031) with TARGET\n",
      "Dropping column APP_EDUCATION due to low correlation (0.058) with TARGET\n",
      "Dropping column APP_TRAVEL_PASS due to low correlation (0.024) with TARGET\n",
      "Dropping column APP_CAR due to low correlation (0.028) with TARGET\n",
      "Dropping column APP_POSITION_TYPE due to low correlation (0.034) with TARGET\n",
      "Dropping column APP_EMP_TYPE due to low correlation (0.030) with TARGET\n",
      "Dropping column DEAL_YQZ_IR_MAX due to low correlation (0.019) with TARGET\n",
      "Dropping column LDEAL_YQZ_COM due to low correlation (-0.028) with TARGET\n",
      "Dropping column DEAL_YQZ_IR_MIN due to low correlation (0.024) with TARGET\n",
      "Dropping column LDEAL_TENOR_MIN due to low correlation (0.024) with TARGET\n",
      "Dropping column APP_COMP_TYPE due to low correlation (0.030) with TARGET\n",
      "Dropping column DEAL_GRACE_DAYS_ACC_S1X1 due to low correlation (-0.003) with TARGET\n",
      "Dropping column AVG_PCT_MONTH_TO_PCLOSE due to low correlation (0.009) with TARGET\n",
      "Dropping column DEAL_YWZ_IR_MIN due to low correlation (-0.016) with TARGET\n",
      "Dropping column DEAL_YWZ_IR_MAX due to low correlation (-0.039) with TARGET\n",
      "Dropping column DEAL_GRACE_DAYS_ACC_AVG due to low correlation (-0.010) with TARGET\n",
      "Dropping column LDEAL_YQZ_PC due to low correlation (0.023) with TARGET\n",
      "Dropping column DEAL_GRACE_DAYS_ACC_MAX due to low correlation (-0.011) with TARGET\n",
      "Dropping column CLNT_SALARY_VALUE due to low correlation (0.012) with TARGET\n",
      "Dropping column LDEAL_USED_AMT_AVG_YQZ due to low correlation (-0.008) with TARGET\n",
      "Dropping column LDEAL_USED_AMT_AVG_YWZ due to low correlation (-0.013) with TARGET\n",
      "Dropping column LDEAL_DELINQ_PER_MAXYWZ due to low correlation (0.001) with TARGET\n",
      "df shape after dropping columns: (355190, 88)\n"
     ]
    }
   ],
   "source": [
    "# Annalyze data whitch to keep or drop\n",
    "print(\"\\nAnalyzing columns with >70% missing values for correlation with TARGET...\")\n",
    "print(f\"df shape before dropping columns: {df.shape}\")\n",
    "high_missing = df.columns[df.isnull().sum() / len(df) > TRESHOLD]\n",
    "for col in high_missing:\n",
    "    if col == 'TARGET':\n",
    "        continue\n",
    "    # coerce to numeric where possible, compute correlation with TARGET\n",
    "    \n",
    "    if df[col].dtype == 'object':\n",
    "        # categorical column\n",
    "        corr = cramers_v(df[col].dropna(), df.loc[df[col].notnull(), 'TARGET'])\n",
    "        if corr < 0.1:\n",
    "            print(f\"Dropping column {col} due to low correlation ({corr:.3f}) with TARGET\")\n",
    "            df = df.drop(columns=[col])\n",
    "    else:\n",
    "        # numerical column\n",
    "        series_num = pd.to_numeric(df[col], errors='coerce')\n",
    "        corr = series_num.corr(df['TARGET'])\n",
    "        if pd.notnull(corr) and abs(corr) < 0.05:\n",
    "            print(f\"Dropping column {col} due to low correlation ({corr:.3f}) with TARGET\")\n",
    "            df = df.drop(columns=[col])\n",
    "    \n",
    "    \n",
    "    # series_num = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # corr = cramers_v(df[col].dropna(), df.loc[df[col].notnull(), 'TARGET'])\n",
    "    # missing_pct = df[col].isnull().sum() / len(df) * 100\n",
    "    # corr_str = f\"{corr:.3f}\" if pd.notnull(corr) else \"N/A\"\n",
    "    # print(f\"{col}: Missing={missing_pct:.1f}%, Correlation={corr_str}\")\n",
    "print(f\"df shape after dropping columns: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52a1da3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLNT_JOB_POSITION: object\n",
      "PACK: object\n"
     ]
    }
   ],
   "source": [
    "for col in df:\n",
    "    column_type = df[col].dtype\n",
    "    if column_type != 'int64' and column_type != 'float64':\n",
    "        print(f\"{col}: {column_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37034e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalize_categorical_columns(df):\n",
    "    \"\"\"\n",
    "    Normalize categorical columns by converting to lowercase/uppercase\n",
    "    and stripping whitespace\n",
    "    \"\"\"\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    for col in cat_cols:\n",
    "        # Convert to string, lowercase, and strip whitespace\n",
    "        df[col] = df[col].astype(str).str.upper()\n",
    "        df[col] = df[col].str.strip()\n",
    "        df[col] = df[col].replace('NAN', np.nan)  # Replace 'NA' strings with NaN\n",
    "        df[col] = df[col].replace('', np.nan)  # Replace empty strings with NaN\n",
    "    \n",
    "    return df\n",
    "df = normalize_categorical_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d153efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLNT_JOB_POSITION: object\n",
      "PACK: object\n",
      "PACK: Missing=0.0%, Correlation=0.071\n",
      "existing_values length: 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'K01': 77083,\n",
       " '102': 116986,\n",
       " '105': 44936,\n",
       " 'O01': 50478,\n",
       " '103': 24860,\n",
       " '101': 1816,\n",
       " '107': 27952,\n",
       " '301': 4208,\n",
       " '104': 6776,\n",
       " '108': 2,\n",
       " '109': 86,\n",
       " 'M01': 7}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df:\n",
    "    column_type = df[col].dtype\n",
    "    if column_type != 'int64' and column_type != 'float64':\n",
    "        print(f\"{col}: {column_type}\")\n",
    "\n",
    "\n",
    "# Count non-null occurrences of each job position\n",
    "existing_values = {}\n",
    "for val in df['PACK']:\n",
    "    if pd.isnull(val):\n",
    "        continue\n",
    "    existing_values[val] = existing_values.get(val, 0) + 1\n",
    "corr = cramers_v(df['PACK'].dropna(), df.loc[df['PACK'].notnull(), 'TARGET'])\n",
    "missing_pct = df['PACK'].isnull().sum() / len(df) * 100\n",
    "print(f\"PACK: Missing={missing_pct:.1f}%, Correlation={corr:.3f}\")\n",
    "print(f\"existing_values length: {len(existing_values)}\")\n",
    "existing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ac3a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_encoders(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Fit encoders on training data and return fitted encoders.\n",
    "    \"\"\"\n",
    "    # Get object columns\n",
    "    obj_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # Try numeric conversion\n",
    "    numeric_conversions = {}\n",
    "    for col in obj_cols:\n",
    "        converted = pd.to_numeric(X_train[col], errors='coerce')\n",
    "        if converted.notna().mean() > 0.9:\n",
    "            numeric_conversions[col] = True\n",
    "    print(\"numeric conversion\", numeric_conversions)\n",
    "    # Update object columns\n",
    "    obj_cols = [col for col in obj_cols if col not in numeric_conversions]\n",
    "    \n",
    "    # Categorize by cardinality\n",
    "    low_card_cols = []\n",
    "    high_card_cols = []\n",
    "    \n",
    "    for col in obj_cols:\n",
    "        if X_train[col].isnull().all():\n",
    "            continue\n",
    "        \n",
    "        unique_count = X_train[col].nunique(dropna=True)\n",
    "        \n",
    "        if unique_count < 10:\n",
    "            low_card_cols.append(col)\n",
    "        else:\n",
    "            high_card_cols.append(col)\n",
    "    \n",
    "    # Fit target encoder on training data\n",
    "    target_encoder = None\n",
    "    if high_card_cols:\n",
    "        target_encoder = ce.TargetEncoder(cols=high_card_cols, smoothing=1.0)\n",
    "        valid_mask = X_train[high_card_cols].notna().all(axis=1) & y_train['TARGET'].notna()\n",
    "        target_encoder.fit(X_train.loc[valid_mask, high_card_cols], y_train.loc[valid_mask, 'TARGET'])\n",
    "    \n",
    "    return {\n",
    "        'numeric_conversions': numeric_conversions,\n",
    "        'low_card_cols': low_card_cols,\n",
    "        'high_card_cols': high_card_cols,\n",
    "        'target_encoder': target_encoder,\n",
    "        'global_mean': y_train['TARGET'].mean()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85945e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_with_encoders(X, encoders_dict):\n",
    "    \"\"\"\n",
    "    Transform data using pre-fitted encoders.\n",
    "    \"\"\"\n",
    "    X = X.copy()\n",
    "    \n",
    "    # Apply numeric conversions\n",
    "    for col in encoders_dict['numeric_conversions']:\n",
    "        X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "    \n",
    "    # Drop all-null columns\n",
    "    obj_cols = X.select_dtypes(include=['object']).columns\n",
    "    for col in obj_cols:\n",
    "        if X[col].isnull().all():\n",
    "            X = X.drop(columns=[col])\n",
    "    \n",
    "    # Target encode high-cardinality columns\n",
    "    if encoders_dict['high_card_cols'] and encoders_dict['target_encoder']:\n",
    "        high_card_cols = encoders_dict['high_card_cols']\n",
    "        print(f\"\\n\\nTarget encoding: {high_card_cols}\\n\\n\")\n",
    "        for col in high_card_cols:\n",
    "            if col in X.columns:\n",
    "                # Transform using fitted encoder\n",
    "                print(f\"Encoding column: {col}\")\n",
    "                print()\n",
    "                try:\n",
    "                    # Transform using the encoder fitted on all high-cardinality cols,\n",
    "                    # then take the encoded series for the current column\n",
    "                    encoded = encoders_dict['target_encoder'].transform(X[encoders_dict['high_card_cols']])[col]\n",
    "                    X[col] = encoded\n",
    "                    # Fill unseen / missing encodings with global mean\n",
    "                    X[col].fillna(encoders_dict['global_mean'], inplace=True)\n",
    "                except Exception:\n",
    "                    # If transform fails, fall back to global mean\n",
    "                    X[col] = encoders_dict['global_mean']\n",
    "        #         X = X.drop(columns=[col])\n",
    "                \n",
    "                \n",
    "                \n",
    "        #         X[f\"{col}\"] = encoded[col]\n",
    "                \n",
    "        #         # Fill nulls with global mean\n",
    "        #         X[f\"{col}\"].fillna(encoders_dict['global_mean'], inplace=True)\n",
    "        \n",
    "        # Drop original columns\n",
    "        # X = X.drop(columns=[col for col in high_card_cols if col in X.columns])\n",
    "    \n",
    "    # One-hot encode low-cardinality columns\n",
    "    if encoders_dict['low_card_cols']:\n",
    "        print(f\"\\nOne-hot encoding: {encoders_dict['low_card_cols']}\")\n",
    "\n",
    "        X = pd.get_dummies(X, columns=encoders_dict['low_card_cols'], drop_first=True)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d72a35ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (284152, 87), Test shape: (71038, 87)\n"
     ]
    }
   ],
   "source": [
    "# split data train test\n",
    "\n",
    "\n",
    "y = pd.DataFrame()\n",
    "y['TARGET'] = df['TARGET']\n",
    "X = df.drop(columns=['TARGET'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                            X,y,\n",
    "                            test_size=0.2,\n",
    "                            random_state=42,\n",
    "                            stratify=y)\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d69295e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting encoders on training data...\n",
      "================================================================================\n",
      "numeric conversion {}\n",
      "numeric_conversions: {}\n",
      "low_card_cols: []\n",
      "high_card_cols: ['CLNT_JOB_POSITION', 'PACK']\n",
      "target_encoder: TargetEncoder(cols=['CLNT_JOB_POSITION', 'PACK'], smoothing=1.0)\n",
      "global_mean: 0.08143528815563501\n"
     ]
    }
   ],
   "source": [
    "# Fit encoders on TRAINING data only\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "print(\"Fitting encoders on training data...\")\n",
    "print(\"=\"*80)\n",
    "encoders = fit_encoders(X_train, y_train)\n",
    "for key, value in encoders.items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05db1825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transforming training data...\n",
      "\n",
      "\n",
      "Target encoding: ['CLNT_JOB_POSITION', 'PACK']\n",
      "\n",
      "\n",
      "Encoding column: CLNT_JOB_POSITION\n",
      "\n",
      "Encoding column: PACK\n",
      "\n",
      "\n",
      "Transforming test data...\n",
      "\n",
      "\n",
      "Target encoding: ['CLNT_JOB_POSITION', 'PACK']\n",
      "\n",
      "\n",
      "Encoding column: CLNT_JOB_POSITION\n",
      "\n",
      "Encoding column: PACK\n",
      "\n",
      "\n",
      "After encoding - Train: (284152, 87), Test: (71038, 87)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6251/204901964.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(encoders_dict['global_mean'], inplace=True)\n",
      "/tmp/ipykernel_6251/204901964.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(encoders_dict['global_mean'], inplace=True)\n",
      "/tmp/ipykernel_6251/204901964.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(encoders_dict['global_mean'], inplace=True)\n",
      "/tmp/ipykernel_6251/204901964.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[col].fillna(encoders_dict['global_mean'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTransforming training data...\")\n",
    "X_train_encoded = transform_with_encoders(X_train, encoders)\n",
    "\n",
    "print(\"\\nTransforming test data...\")\n",
    "X_test_encoded = transform_with_encoders(X_test, encoders)\n",
    "\n",
    "\n",
    "print(f\"\\nAfter encoding - Train: {X_train_encoded.shape}, Test: {X_test_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "721347ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aligning train/test columns...\n"
     ]
    }
   ],
   "source": [
    "# Just to make sure not needed in our case -------------------------------------\n",
    "# Align columns (ensure train and test have same columns)\n",
    "print(\"\\nAligning train/test columns...\")\n",
    "train_cols = set(X_train_encoded.columns)\n",
    "test_cols = set(X_test_encoded.columns)\n",
    "\n",
    "# Add missing columns to test (fill with 0)\n",
    "for col in train_cols - test_cols:\n",
    "    X_test_encoded[col] = 0\n",
    "    print(f\"Added missing column to test: {col}\")\n",
    "\n",
    "# Remove extra columns from test\n",
    "for col in test_cols - train_cols:\n",
    "    X_test_encoded = X_test_encoded.drop(columns=[col])\n",
    "    print(f\"Removed extra column from test: {col}\")\n",
    "#-------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "282f6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder test columns to match train\n",
    "\n",
    "#! Mandatory step to ensure columns are in the same order after encoding\n",
    "\n",
    "X_test_encoded = X_test_encoded[X_train_encoded.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4e37337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train nulls: 8813805\n",
      "Test nulls: 2202381\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTrain nulls: {X_train_encoded.isnull().sum().sum()}\")\n",
    "print(f\"Test nulls: {X_test_encoded.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bdd56fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After fillna with mean\n",
      "Train nulls: 0\n",
      "Test nulls: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6251/4282412580.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train_encoded[col].fillna(imputation_values[col], inplace=True)\n",
      "/tmp/ipykernel_6251/4282412580.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test_encoded[col].fillna(imputation_values[col], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "imputation_values = X_train_encoded.mean()\n",
    "\n",
    "for col in X_train_encoded.columns:\n",
    "    if X_train_encoded[col].isnull().any():\n",
    "        X_train_encoded[col].fillna(imputation_values[col], inplace=True)\n",
    "    \n",
    "    if X_test_encoded[col].isnull().any():\n",
    "        X_test_encoded[col].fillna(imputation_values[col], inplace=True)\n",
    "print(f\"\\nAfter fillna with mean\\nTrain nulls: {X_train_encoded.isnull().sum().sum()}\")\n",
    "print(f\"Test nulls: {X_test_encoded.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a7f235e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing training set using SMOTE...\n",
      "Before SMOTE: TARGET\n",
      "0    261012\n",
      "1     23140\n",
      "Name: count, dtype: int64 | X shape: (284152, 87)\n",
      "After SMOTE: TARGET\n",
      "0    261012\n",
      "1    261012\n",
      "Name: count, dtype: int64 | X shape: (522024, 87)\n"
     ]
    }
   ],
   "source": [
    "# Balence Dataset for training set only\n",
    "\n",
    "print(\"Balancing training set using SMOTE...\")\n",
    "print(f\"Before SMOTE: {y_train['TARGET'].value_counts()} | X shape: {X_train_encoded.shape}\")\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_encoded, y_train)\n",
    "print(f\"After SMOTE: {y_train_balanced['TARGET'].value_counts()} | X shape: {X_train_balanced.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
